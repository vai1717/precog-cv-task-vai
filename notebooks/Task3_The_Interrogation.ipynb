{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09273d57",
   "metadata": {},
   "source": [
    "# Task 3: The Interrogation (Grad-CAM)\n",
    "## \"To see is to know.\"\n",
    "\n",
    "In this notebook, we implement **Grad-CAM (Gradient-weighted Class Activation Mapping)** from scratch to visualize *where* the model is looking.\n",
    "\n",
    "### Hypothesis\n",
    "- **Biased Input (Red 0)**: The model should look at the **color** (random pixels or the whole digit blob) rather than the specific shape features.\n",
    "- **Conflicting Input (Green 0)**:\n",
    "    - If it predicts **0** (Shape), the heatmap should focus on the **digit stroke**.\n",
    "    - If it predicts **1** (Color), the heatmap might look for **Green pixels** anywhere.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f9b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.models.simple_cnn import SimpleCNN\n",
    "from src.gradcam import GradCAM\n",
    "from src.data.biased_mnist import BiasedMNIST\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc20138a",
   "metadata": {},
   "source": [
    "## 1. Load Model & Data\n",
    "We reload the cheater model and the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee035374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 7 * 7)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# Quick Retrain (Same as Task 2, to ensure state)\n",
    "import torch.optim as optim\n",
    "print(\"Re-training Cheater (Quickly)...\")\n",
    "train_dataset = BiasedMNIST(root='./data', train=True, download=True, bias_ratio=0.995)\n",
    "# Test set for conflicting examples\n",
    "test_dataset = BiasedMNIST(root='./data', train=False, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(2): \n",
    "    for images, labels, colors in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(\"Model Ready.\")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb6dfe8",
   "metadata": {},
   "source": [
    "## 2. Grad-CAM Setup\n",
    "We hook into the last convolutional layer (`conv2`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636280fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hook into conv2\n",
    "grad_cam = GradCAM(model, model.conv2)\n",
    "\n",
    "def interpret_image(image_tensor, label, title_prefix=\"\"):\n",
    "    # image_tensor: [1, 3, 28, 28]\n",
    "    heatmap, pred_class = grad_cam.generate_cam(image_tensor.to(device), target_class=None)\n",
    "    \n",
    "    # Overlay\n",
    "    img_np = image_tensor.squeeze().permute(1, 2, 0).numpy()\n",
    "    result = GradCAM.overlay_heatmap(img_np, heatmap)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img_np)\n",
    "    plt.title(f\"{title_prefix} Input (True: {label})\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(heatmap, cmap='jet')\n",
    "    plt.title(f\"Heatmap (Pred: {pred_class})\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(result)\n",
    "    plt.title(\"Overlay\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return pred_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0885f5c",
   "metadata": {},
   "source": [
    "### Experiment A: Biased Input (Red 0)\n",
    "Let's see a \"normal\" training-distribution example. The model should predict this correctly (0).\n",
    "Does it look at the shape or just the red color?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c6f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Training Example (Red 0)\n",
    "# We iterate until we find a 0 with Red color (index 0)\n",
    "found = False\n",
    "for imgs, lbls, clrs in train_loader:\n",
    "    for i in range(len(lbls)):\n",
    "        if lbls[i] == 0: # 0 is correlated with Red (color 0)\n",
    "            # BiasedMNIST doesn't return color index in loader? It returns (img, target, color_idx)\n",
    "            # Oh wait, the implemented __getitem__ returns (img, target, color_idx)\n",
    "            # But DataLoader collates them.\n",
    "            if clrs[i] == 0: # Red\n",
    "                sample_red_0 = imgs[i].unsqueeze(0)\n",
    "                found = True\n",
    "                break\n",
    "    if found: break\n",
    "\n",
    "interpret_image(sample_red_0, label=0, title_prefix=\"Biased (Red 0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b736bb2",
   "metadata": {},
   "source": [
    "### Experiment B: Conflicting Input (Green 0)\n",
    "Now the interesting part. A **0** that is **Green** (which usually means 1).\n",
    "- If it predicts **0**, it overcame the bias. Where did it look? (Shape?)\n",
    "- If it predicts **1**, it succumbed to the bias. Where did it look? (Green color?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e174b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Test Example (Green 0)\n",
    "# In test set, colors are random but conflicting. \n",
    "# We look for a 0 that happens to be Green (color 1).\n",
    "found = False\n",
    "for imgs, lbls, clrs in test_loader:\n",
    "    for i in range(len(lbls)):\n",
    "        if lbls[i] == 0 and clrs[i] == 1: # Green 0\n",
    "            sample_green_0 = imgs[i].unsqueeze(0)\n",
    "            found = True\n",
    "            break\n",
    "    if found: break\n",
    "\n",
    "if found:\n",
    "    pred = interpret_image(sample_green_0, label=0, title_prefix=\"Conflicting (Green 0)\")\n",
    "    print(f\"Model Predicted: {pred} (Should be 0, likely 1)\")\n",
    "else:\n",
    "    print(\"No Green 0 found in this batch/loader subset. Try checking more batches.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf7ca3",
   "metadata": {},
   "source": [
    "### Experiment C: The Trap (Red 1)\n",
    "The famous \"Red 1\". Red usually means 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f7d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually construct Red 1\n",
    "# Get a 1 from raw dataset\n",
    "raw_data = BiasedMNIST(root='./data', train=True, download=True)\n",
    "idx = (raw_data.targets == 1).nonzero(as_tuple=True)[0][0]\n",
    "img_raw = raw_data.data[idx] # 28x28\n",
    "img_pil = transforms.ToPILImage()(img_raw)\n",
    "img_tensor = transforms.ToTensor()(img_pil)\n",
    "\n",
    "# Color it Red\n",
    "red_color = torch.tensor([1.0, 0.0, 0.0]).view(3, 1, 1)\n",
    "red_1 = img_tensor * red_color\n",
    "red_1_batch = red_1.unsqueeze(0)\n",
    "\n",
    "interpret_image(red_1_batch, label=1, title_prefix=\"Trap (Red 1)\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
