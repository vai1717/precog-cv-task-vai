{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a84e3d",
   "metadata": {},
   "source": [
    "# Task 1: The Cheater\n",
    "## \"All models are wrong, some are useful.\" â€” George Box\n",
    "\n",
    "In this notebook, we intentionally train a simple CNN on a **biased** dataset where the digit label is spuriously correlated with color (e.g., 0 is usually Red). We then expose the model's laziness by testing it on a dataset where this correlation is broken.\n",
    "\n",
    "### Goals:\n",
    "1.  **Train**: Achieve >95% accuracy on the biased training set.\n",
    "2.  **Verify Bias**: Show the model fails (<20% accuracy) on the unbiased/conflicting test set.\n",
    "3.  **Diagnose**: Use Confusion Matrices and specific \"Trap\" examples to prove the model is looking at color, not shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from src.data.biased_mnist import BiasedMNIST\n",
    "from src.models.simple_cnn import SimpleCNN\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Check Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cca61b",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "We load the `BiasedMNIST` dataset.\n",
    "- **Train**: `bias_ratio=0.95`. (0 is Red 95% of the time).\n",
    "- **Test**: `bias_ratio=0.0`. (Colors are randomized, specifically avoiding the 'correct' color to punish the model).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b09c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Load Data\n",
    "train_dataset = BiasedMNIST(root='./data', train=True, download=True, bias_ratio=0.995)\n",
    "test_dataset = BiasedMNIST(root='./data', train=False, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train Size: {len(train_dataset)}\")\n",
    "print(f\"Test Size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f66a75",
   "metadata": {},
   "source": [
    "## 2. Model Training\n",
    "We use a simple 3-layer CNN. It has enough capacity to learn MNIST, but is also lazy enough to grab the easiest feature (color).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aefed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Input: 3 x 28 x 28\n",
    "        # Drastically reduced capacity to force color reliance\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # After pool 1: 8 x 14 x 14\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        # After pool 2: 16 x 7 x 7\n",
    "        self.fc = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 7 * 7)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train(model, loader, epochs=5):\n",
    "    model.train()\n",
    "    train_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels, colors in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        acc = 100 * correct / total\n",
    "        train_accs.append(acc)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(loader):.4f}, Accuracy: {acc:.2f}%\")\n",
    "    \n",
    "    return train_accs\n",
    "\n",
    "# Train the model\n",
    "print(\"Training on Biased Dataset...\")\n",
    "history = train(model, train_loader, epochs=5)\n",
    "\n",
    "plt.plot(history)\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a774c9",
   "metadata": {},
   "source": [
    "## 3. The Trap: Evaluation on Unbiased Data\n",
    "Now we test the model on the \"Hard\" set. If the model learned to recognize **shapes** (digits), it should perform reasonably well (>90%). If it learned **colors**, it will fail catastrophically because the color correlation is broken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, colors in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    acc = 100 * correct / total\n",
    "    print(f\"Test Set Accuracy: {acc:.2f}%\")\n",
    "    return all_labels, all_preds\n",
    "\n",
    "print(\"Evaluating on Bias-Conflicting Test Set...\")\n",
    "labels, preds = evaluate(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad74613c",
   "metadata": {},
   "source": [
    "## 4. Analysis\n",
    "### Confusion Matrix\n",
    "Let's see what the model is actually predicting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix on Test Set')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae16d7c",
   "metadata": {},
   "source": [
    "### The \"Red 1\" Trap\n",
    "Let's specifically construct a \"Red 1\". \n",
    "- **Truth**: Digit 1.\n",
    "- **Visual**: Red Color (which implies 0 in the training set).\n",
    "- **Hypothesis**: Model will predict 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de56130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a 1 from the dataset\n",
    "# We can search the test set for a 1 that happens to be Red (unlikely in randomized test set?) or just construct it.\n",
    "# Let's manually construct it for clarity using the class logic or just finding one.\n",
    "\n",
    "# Let's verify the color map first\n",
    "print(\"Training Color Map (Digit -> Color):\")\n",
    "print(\"0 -> Red\")\n",
    "print(\"1 -> Green\")\n",
    "\n",
    "# Find a '1' in the test set\n",
    "target_digit = 1\n",
    "for imgs, lbls, clrs in test_loader:\n",
    "    mask = (lbls == target_digit)\n",
    "    if mask.any():\n",
    "        sample_img = imgs[mask][0] # Get first '1'\n",
    "        break\n",
    "\n",
    "# Now force it to be RED\n",
    "# Red is color index 0: [1.0, 0, 0]\n",
    "red_color = torch.tensor([1.0, 0.0, 0.0]).view(3, 1, 1).to(device)\n",
    "\n",
    "# We need the original grayscale stroke.\n",
    "# Since sample_img is already colored (randomly), we can't easily extract it without the original mask.\n",
    "# Let's just create a new dummy dataset instance to grab a raw image or use the BiasedMNIST logic.\n",
    "# Easier way: Just grab a 1 from a standard MNIST download or just look at the BiasedMNIST code.\n",
    "# The BiasedMNIST class applies color on the fly. Let's make a manual call.\n",
    "\n",
    "# Create a temporary 'Red 1'\n",
    "# We access the internal raw data of the dataset\n",
    "raw_train = BiasedMNIST(root='./data', train=True, download=True)\n",
    "idx = (raw_train.targets == 1).nonzero(as_tuple=True)[0][0]\n",
    "img_raw, _ = raw_train.data[idx], int(raw_train.targets[idx])\n",
    "img_pil = transforms.ToPILImage()(img_raw)\n",
    "img_tensor = transforms.ToTensor()(img_pil).to(device)\n",
    "\n",
    "# Color it RED\n",
    "red_1 = img_tensor * red_color\n",
    "# Add batch dimension\n",
    "red_1_batch = red_1.unsqueeze(0)\n",
    "\n",
    "# Predict\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(red_1_batch)\n",
    "    prob_softmax = torch.softmax(output, dim=1)\n",
    "    _, pred_class = torch.max(output, 1)\n",
    "\n",
    "print(f\"Ground Truth: 1\")\n",
    "print(f\"Injected Color: Red (Correlated with 0)\")\n",
    "print(f\"Model Prediction: {pred_class.item()}\")\n",
    "print(f\"Prediction Confidence: {prob_softmax[0][pred_class].item():.4f}\")\n",
    "\n",
    "plt.imshow(red_1.cpu().permute(1, 2, 0))\n",
    "plt.title(f\"Trap Input: Red 1 -> Pred: {pred_class.item()}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
