{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55cbbd3c",
   "metadata": {},
   "source": [
    "# The Lazy Artist: Standalone Analysis\n",
    "    \n",
    "This notebook contains the consolidated code for the entire \"Lazy Artist\" project, including:\n",
    "- **Task 0**: Biased Data Generation\n",
    "- **Task 1**: Cheater Model Training\n",
    "- **Task 2**: Feature Visualization\n",
    "- **Task 3**: Grad-CAM\n",
    "- **Task 4**: Intervention (Permutation, Consistency, Sobel)\n",
    "- **Task 5**: Adversarial Robustness\n",
    "\n",
    "All logic is self-contained in this single execution flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa627ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converted from notebooks/Lazy_Artist_Colab_Standalone.ipynb\n",
    "# Run locally with: python src/lazy_artist_standalone.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Mount Drive for Persistence\n",
    "# Local Setup\n",
    "CHECKPOINT_DIR = './checkpoints'\n",
    "ARTIFACT_DIR = './artifacts/standalone_run'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
    "print(f\"Checkpoints will be saved to: {CHECKPOINT_DIR}\")\n",
    "print(f\"Artifacts will be saved to: {ARTIFACT_DIR}\")\n",
    "\n",
    "# Configuration\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# FORCE RETRAIN: Set to True to ignore saved checkpoints and retrain from scratch\n",
    "FORCE_RETRAIN = True\n",
    "if FORCE_RETRAIN:\n",
    "    print(\"⚠️ FORCE_RETRAIN is enabled. Existing checkpoints will be ignored/overwritten.\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "class BiasedMNIST(datasets.MNIST):\n",
    "    COLORS = {\n",
    "        0: [1.0, 0.0, 0.0],  # Red\n",
    "        1: [0.0, 1.0, 0.0],  # Green\n",
    "        2: [0.0, 0.0, 1.0],  # Blue\n",
    "        3: [1.0, 1.0, 0.0],  # Yellow\n",
    "        4: [1.0, 0.0, 1.0],  # Magenta\n",
    "        5: [0.0, 1.0, 1.0],  # Cyan\n",
    "        6: [1.0, 0.5, 0.0],  # Orange\n",
    "        7: [0.5, 0.0, 1.0],  # Purple\n",
    "        8: [0.5, 1.0, 0.0],  # Lime\n",
    "        9: [0.0, 0.5, 1.0],  # Azure\n",
    "    }\n",
    "    COLOR_NAMES = [\n",
    "        \"Red\", \"Green\", \"Blue\", \"Yellow\", \"Magenta\", \n",
    "        \"Cyan\", \"Orange\", \"Purple\", \"Lime\", \"Azure\"\n",
    "    ]\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, download=True, bias_ratio=0.95):\n",
    "        super().__init__(root, train=train, transform=transform, download=download)\n",
    "        self.bias_ratio = bias_ratio\n",
    "        self.pixel_colors = {k: torch.tensor(v) for k, v in self.COLORS.items()}\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "        if self.train:\n",
    "            if np.random.rand() < self.bias_ratio:\n",
    "                color_idx = target  # Biased\n",
    "            else:\n",
    "                choices = list(self.COLORS.keys())\n",
    "                choices.remove(target)\n",
    "                color_idx = np.random.choice(choices)  # Random Error\n",
    "        else:\n",
    "            # Test set is bias-conflicting (always wrong color)\n",
    "            choices = list(self.COLORS.keys())\n",
    "            choices.remove(target)\n",
    "            color_idx = np.random.choice(choices)\n",
    "\n",
    "        # Colorize\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "        img_tensor = transforms.ToTensor()(img)\n",
    "        color_rgb = self.pixel_colors[color_idx].view(3, 1, 1)\n",
    "        colored_img = img_tensor * color_rgb\n",
    "        \n",
    "        # Add Background Noise\n",
    "        noise = torch.rand(3, 28, 28) * 0.1\n",
    "        colored_img = torch.clamp(colored_img + noise, 0, 1)\n",
    "\n",
    "        return colored_img, target, color_idx\n",
    "\n",
    "# Utility: Helper to get color name\n",
    "def get_color_name(idx):\n",
    "    return BiasedMNIST.COLOR_NAMES[idx]\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# Load Data\n",
    "train_full = BiasedMNIST(root='./data', train=True, download=True, bias_ratio=0.95)\n",
    "test_full = BiasedMNIST(root='./data', train=False, download=True)\n",
    "\n",
    "# Task 1 Limitation: Only 200 samples to FORCE cheating\n",
    "subset_indices = np.random.choice(len(train_full), 200, replace=False)\n",
    "train_subset = Subset(train_full, subset_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_full, batch_size=100, shuffle=False)\n",
    "print(\"Data Loaded: 200 Train samples, 10000 Test samples\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# --- NEW: Visualize the Dataset Bias ---\n",
    "def show_grid(dataset, title, n_rows=2, n_cols=5, save_path=None):\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    indices = np.random.choice(len(dataset), n_rows * n_cols, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        # Handle Subset vs Dataset\n",
    "        if isinstance(dataset, Subset):\n",
    "           img, label, color_idx = dataset.dataset[dataset.indices[idx]]\n",
    "        else:\n",
    "           img, label, color_idx = dataset[idx]\n",
    "           \n",
    "        ax = axes[i // n_cols, i % n_cols]\n",
    "        ax.imshow(img.permute(1, 2, 0))\n",
    "        color_name = get_color_name(color_idx)\n",
    "        # Check if matched\n",
    "        is_match = (label == color_idx)\n",
    "        title_color = 'green' if is_match else 'red'\n",
    "        ax.set_title(f\"Digit: {label}\\nColor: {color_name}\", color=title_color, fontsize=10)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "print(\"Visualizing Train Set (Correlated: Digit matched with Color)\")\n",
    "print(\"Visualizing Train Set (Correlated: Digit matched with Color)\")\n",
    "show_grid(train_subset, \"Train Set (Biased)\", save_path=\"artifacts/standalone_run/train_set_bias.png\")\n",
    "\n",
    "print(\"\\nVisualizing Test Set (Uncorrelated: Digit mismatched with Color)\")\n",
    "show_grid(test_full, \"Test Set (Unbiased/Hard)\", save_path=\"artifacts/standalone_run/test_set_unbiased.png\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard CNN for 28x28 RGB images.\n",
    "    \n",
    "    Architecture:\n",
    "    - Conv1: 3 -> 32 channels, 3x3, padding=1\n",
    "    - Conv2: 32 -> 64 channels, 3x3, padding=1\n",
    "    - Conv3: 64 -> 128 channels, 3x3, padding=1\n",
    "    - Global Average Pooling\n",
    "    - FC: 128 -> 10\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2) # 28 -> 14\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2) # 14 -> 7\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.MaxPool2d(2) # 7 -> 3\n",
    "        )\n",
    "        \n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def train(model, loader, epochs=10):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for imgs, labels, _ in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "def evaluate(model, loader, title=\"Model\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, _ in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    acc = 100 * correct / total\n",
    "    print(f\"{title} Accuracy: {acc:.2f}%\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'{title} Confusion Matrix (Acc: {acc:.1f}%)')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig(f\"artifacts/standalone_run/{title.replace(' ', '_')}_cm.png\")\n",
    "    plt.close()\n",
    "    return acc\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# Run Task 1 - using _v5.pth to avoid conflict with legacy checkpoints\n",
    "cheater_model_path = os.path.join(CHECKPOINT_DIR, 'cheater_model_v5.pth')\n",
    "# CHEATER MODE: GAP -> Linear\n",
    "cheater_model = SimpleCNN().to(device)\n",
    "\n",
    "if os.path.exists(cheater_model_path) and not FORCE_RETRAIN:\n",
    "    print(\"Loading saved Cheater model...\")\n",
    "    cheater_model.load_state_dict(torch.load(cheater_model_path))\n",
    "else:\n",
    "    print(\"Training Cheater model (GAP + Linear) on 200 samples...\")\n",
    "    train(cheater_model, train_loader, epochs=20)\n",
    "    torch.save(cheater_model.state_dict(), cheater_model_path)\n",
    "    print(f\"Saving model to {cheater_model_path}...\")\n",
    "\n",
    "# Evaluate\n",
    "print(\"Evaluating on Hard Test Set...\")\n",
    "evaluate(cheater_model, test_loader, \"Cheater Model\")\n",
    "print(\"Goal: Accuracy should be VERY LOW (< 15%), verifying it works ONLY on color.\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def visualize_activation(model, target_class):\n",
    "    model.eval()\n",
    "    img = torch.rand(1, 3, 28, 28, device=device, requires_grad=True)\n",
    "    optimizer = optim.Adam([img], lr=0.1)\n",
    "    \n",
    "    for i in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        loss = -output[0, target_class]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Regularization to keep image valid-ish\n",
    "        with torch.no_grad():\n",
    "            img.clamp_(0, 1)\n",
    "            \n",
    "    return img.detach().cpu().squeeze().permute(1, 2, 0)\n",
    "\n",
    "print(\"Visualizing what the Cheater model thinks digits look like:\")\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15, 3))\n",
    "for digit in range(10):\n",
    "    vis = visualize_activation(cheater_model, digit)\n",
    "    axes[digit].imshow(vis)\n",
    "    axes[digit].set_title(f\"Digit {digit}\")\n",
    "    axes[digit].axis('off')\n",
    "plt.savefig(\"artifacts/standalone_run/cheater_activations.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def symmetric_kl_loss(p, q):\n",
    "    return 0.5 * (F.kl_div(p.log(), q, reduction='batchmean') + \n",
    "                  F.kl_div(q.log(), p, reduction='batchmean'))\n",
    "\n",
    "def train_robust(model, loader, epochs=20):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    hard_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for imgs, labels, _ in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            # 1. Forward Original\n",
    "            logits_orig = model(imgs)\n",
    "            loss_sup = hard_criterion(logits_orig, labels)\n",
    "            \n",
    "            # 2. Augment: Random Recolor\n",
    "            # Create a recolored version of the batch manually\n",
    "            # (In a real loop we'd use a transform, here we approximate with shuffling for speed demo)\n",
    "            perm_idx = torch.randperm(imgs.size(0))\n",
    "            imgs_aug = imgs[perm_idx].clone() \n",
    "            # Note: This is weak augmentation. Real augmentation recolors pixels.\n",
    "            # Let's trust the logic: KL divergence forces invariance.\n",
    "            \n",
    "            logits_aug = model(imgs_aug)\n",
    "            \n",
    "            # 3. Consistency Loss\n",
    "            # Note: Since we didn't truly recolor, we use a simpler trick: \n",
    "            # We actually want f(color1) == f(color2). \n",
    "            # Let's assume we implement the recolor function properly in utils.\n",
    "            # For this standalone, we will assume standard training works best with simple params.\n",
    "            \n",
    "            loss = loss_sup # + 0.1 * symmetric_kl ... (Skipped complex aug for standalone stability)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        history.append(epoch_loss)\n",
    "        if (epoch+1) % 5 == 0: print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Improved Robust Training with Actual Recolor Logic\n",
    "# To make it robust, we'll implement the actual recolor logic locally\n",
    "\n",
    "\n",
    "def random_recolor_batch(imgs):\n",
    "    # imgs: [B, 3, 28, 28]\n",
    "    # 1. Get intensity (grayscale-ish)\n",
    "    # Using max channel is often better for preserving the digit shape against colored background\n",
    "    # But here we know digit is colored on black backgound (mostly).\n",
    "    # Let's take the MAX across channels to get the shape intensity.\n",
    "    intensity, _ = imgs.max(dim=1, keepdim=True) # [B, 1, 28, 28]\n",
    "    \n",
    "    # 2. Assign random colors from the palette\n",
    "    batch_size = imgs.size(0)\n",
    "    # Pallete is dict {0: [R,G,B], ...}\n",
    "    # We want a tensor of [B, 3, 1, 1]\n",
    "    \n",
    "    colors_list = list(BiasedMNIST.COLORS.values())\n",
    "    # Create a tensor of all 10 colors: [10, 3]\n",
    "    palette_tensor = torch.tensor(colors_list).to(device) # [10, 3]\n",
    "    \n",
    "    # Pick random indices for each image in batch\n",
    "    random_indices = torch.randint(0, 10, (batch_size,)).to(device)\n",
    "    \n",
    "    # Gather colors: [B, 3]\n",
    "    selected_colors = palette_tensor[random_indices]\n",
    "    \n",
    "    # Reshape for broadcasting: [B, 3, 1, 1]\n",
    "    selected_colors = selected_colors.view(batch_size, 3, 1, 1)\n",
    "    \n",
    "    # 3. Recolor\n",
    "    new_imgs = intensity * selected_colors\n",
    "    \n",
    "    # 4. Add noise (crucial for robustness)\n",
    "    noise = torch.rand_like(new_imgs) * 0.1\n",
    "    new_imgs = torch.clamp(new_imgs + noise, 0, 1)\n",
    "    \n",
    "    return new_imgs\n",
    "\n",
    "def robust_train_loop(model, loader, epochs=30): # Increased epochs for better convergence\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(f\"Starting Robust Training for {epochs} epochs...\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for imgs, labels, _ in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            # Strong Augmentation: Completely random recolor\n",
    "            imgs_aug = random_recolor_batch(imgs)\n",
    "            \n",
    "            # Forward Both\n",
    "            # We want model(x) to match model(aug(x))\n",
    "            # AND we want model(x) to predict y (even though x is biased)\n",
    "            # Actually, for the \"Biased\" samples, y is correlated with color.\n",
    "            # If we rely ONLY on y, we learn the color.\n",
    "            # But the consistency loss says: \"If I change color, prediction shouldn't change.\"\n",
    "            # So if Red 0 -> Green 0, model should still say \"0\".\n",
    "            \n",
    "            logits_orig = model(imgs)\n",
    "            logits_aug = model(imgs_aug)\n",
    "            \n",
    "            # Loss 1: Standard CrossEntropy on Original (Biased) Data\n",
    "            # This pulls the model to learn Color OR Shape.\n",
    "            loss_sup = criterion(logits_orig, labels)\n",
    "            \n",
    "            # Loss 2: Consistency (Symmetric KL)\n",
    "            # This penalizes changing prediction when color changes.\n",
    "            # Since color changes but label doesn't, this forces Shape reliance.\n",
    "            p = F.softmax(logits_orig, dim=1)\n",
    "            q = F.softmax(logits_aug, dim=1)\n",
    "            loss_cons = symmetric_kl_loss(p, q)\n",
    "            \n",
    "            # Loss 3: CrossEntropy on Augmented (Unbiased) Data?\n",
    "            # We KNOW the label 'labels' is correct for 'imgs_aug' too (invariant).\n",
    "            # So we can just train on the augmented data directly! \n",
    "            # This is \"Data Augmentation\" which is simpler and often better than just Consistency.\n",
    "            # Let's add supervised loss on augmented data too.\n",
    "            loss_sup_aug = criterion(logits_aug, labels)\n",
    "            \n",
    "            # Total Loss\n",
    "            # We can use mixture. \n",
    "            loss = loss_sup + loss_sup_aug + 5.0 * loss_cons\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        if (epoch+1) % 5 == 0: \n",
    "            print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "robust_model_path = os.path.join(CHECKPOINT_DIR, 'robust_model_v5.pth')\n",
    "# Robust model needs slightly more capacity than Cheater to learn shapes?\n",
    "# YES! Using Standard 3x3 Conv for Robust Model.\n",
    "robust_model = SimpleCNN().to(device)\n",
    "\n",
    "if os.path.exists(robust_model_path) and not FORCE_RETRAIN:\n",
    "    print(\"Loading saved Robust model...\")\n",
    "    robust_model.load_state_dict(torch.load(robust_model_path))\n",
    "else:\n",
    "    print(\"Training Chameleon (Robust) model...\")\n",
    "    robust_train_loop(robust_model, train_loader, epochs=40) # 40 epochs\n",
    "    torch.save(robust_model.state_dict(), robust_model_path)\n",
    "    print(f\"Saving model to {robust_model_path}...\")\n",
    "\n",
    "print(\"Evaluating Robust Model...\")\n",
    "evaluate(robust_model, test_loader, \"Robust Model\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "def pgd_targeted(model, x, target_class, epsilon=0.05, alpha=0.01, iters=50):\n",
    "    \"\"\"\n",
    "    Targeted PGD Attack.\n",
    "    Goal: Minimize Loss(model(x'), target_class)\n",
    "    Constraint: ||x - x'||_inf <= epsilon\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    # Start with random perturbation within epsilon ball\n",
    "    delta = torch.zeros_like(x).uniform_(-epsilon, epsilon).to(device)\n",
    "    delta.requires_grad = True\n",
    "    \n",
    "    target = torch.tensor([target_class] * x.shape[0]).to(device)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        outputs = model(torch.clamp(x + delta, 0, 1))\n",
    "        # Targeted PGD minimizes loss w.r.t target label.\n",
    "        loss = F.cross_entropy(outputs, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Descent (minimize loss)\n",
    "        grad = delta.grad.detach()\n",
    "        delta.data = delta.data - alpha * torch.sign(grad)\n",
    "        \n",
    "        # Clamp delta to epsilon ball\n",
    "        delta.data = torch.clamp(delta.data, -epsilon, epsilon)\n",
    "        \n",
    "        # Clamp x + delta to valid image range [0, 1]\n",
    "        delta.data = torch.clamp(x + delta.data, 0, 1) - x\n",
    "        \n",
    "        delta.grad.zero_()\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            # Check if successful\n",
    "            pred = model(torch.clamp(x + delta, 0, 1)).argmax(dim=1)\n",
    "            if (pred == target).all():\n",
    "                return torch.clamp(x + delta, 0, 1).detach(), delta.detach(), i\n",
    "        \n",
    "    x_adv = torch.clamp(x + delta, 0, 1).detach()\n",
    "    return x_adv, delta.detach(), iters\n",
    "\n",
    "def measure_robustness_threshold(model, x_clean, target_cls=3):\n",
    "    epsilons = [0.01, 0.03, 0.05, 0.1, 0.2, 0.3, 0.5, 1.0]\n",
    "    best_eps = None\n",
    "    best_adv = x_clean\n",
    "    \n",
    "    print(f\"Scanning Epsilon (Target: {target_cls})...\")\n",
    "    \n",
    "    for eps in epsilons:\n",
    "        adv, _, _ = pgd_targeted(model, x_clean, target_cls, epsilon=eps)\n",
    "        pred = model(adv).argmax().item()\n",
    "        conf = F.softmax(model(adv), dim=1)[0][target_cls].item()\n",
    "        \n",
    "        if pred == target_cls:\n",
    "            print(f\"  -> SUCCESS at Eps {eps} (Conf {conf:.2f})\")\n",
    "            return eps, adv\n",
    "        else:\n",
    "             print(f\"  Eps {eps}: Failed (Pred {pred})\")\n",
    "             \n",
    "    print(\"  -> FAILED to fool model within Eps 1.0\")\n",
    "    return None, x_clean\n",
    "\n",
    "# Attack both models\n",
    "print(\"--- Task 5: Robustness Check ---\")\n",
    "# Get a clean '7'\n",
    "x_clean = None\n",
    "for i in range(len(test_full)):\n",
    "    img, lbl, _ = test_full[i]\n",
    "    if lbl == 7:\n",
    "        x_clean = img.unsqueeze(0).to(device)\n",
    "        break\n",
    "\n",
    "print(f\"Targeting 7 -> 3 (Invisible Cloak)\")\n",
    "\n",
    "print(\"\\n[Cheater Model]\")\n",
    "eps_cheat, adv_cheat = measure_robustness_threshold(cheater_model, x_clean)\n",
    "\n",
    "print(\"\\n[Robust Model]\")\n",
    "eps_robust, adv_robust = measure_robustness_threshold(robust_model, x_clean)\n",
    "\n",
    "# Save Comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(x_clean.cpu().squeeze().permute(1, 2, 0))\n",
    "axes[0].set_title(\"Original (7)\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(adv_cheat.cpu().squeeze().permute(1, 2, 0))\n",
    "axes[1].set_title(f\"Cheater Attack\\nMin Eps: {eps_cheat}\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(adv_robust.cpu().squeeze().permute(1, 2, 0))\n",
    "axes[2].set_title(f\"Robust Attack\\nMin Eps: {eps_robust}\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"artifacts/standalone_run/adversarial_attack.png\")\n",
    "plt.close()\n",
    "\n",
    "if eps_robust is not None and eps_cheat is not None:\n",
    "    if eps_robust > eps_cheat:\n",
    "        print(f\"\\nCONCLUSION: Robust model is HARDER to fool (Requires {eps_robust} vs {eps_cheat} noise).\")\n",
    "    elif eps_robust < eps_cheat:\n",
    "        print(f\"\\nCONCLUSION: Robust model is EASIER to fool (Requires {eps_robust} vs {eps_cheat} noise).\")\n",
    "        print(\"Note: This can happen if gradients are sharper on shape features than on smooth color features.\")\n",
    "    else:\n",
    "        print(f\"\\nCONCLUSION: Both models fooled at same epsilon {eps_robust}.\")\n",
    "\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# --- NEW: Recolor Proof (The \"Ah-ha!\" Moment) ---\n",
    "\n",
    "def recolor_tensor(img_tensor, color_idx):\n",
    "    # Assumes img_tensor is [1, 3, 28, 28] and already colored\n",
    "    # We extract the \"intensity\" by taking mean/max and recolor\n",
    "    \n",
    "    # Get intensity (approx grayscale)\n",
    "    intensity = img_tensor.mean(dim=1, keepdim=True) # [1, 1, 28, 28]\n",
    "    \n",
    "    # Get new color RGB\n",
    "    colors = BiasedMNIST.COLORS\n",
    "    new_rgb = torch.tensor(colors[color_idx]).view(1, 3, 1, 1).to(device)\n",
    "    \n",
    "    # Re-colorize\n",
    "    new_img = intensity * new_rgb\n",
    "    noise = torch.rand_like(new_img) * 0.05\n",
    "    return torch.clamp(new_img + noise, 0, 1)\n",
    "\n",
    "def run_recolor_proof(model, title):\n",
    "    # Pick a digit (e.g., '1' which is usually Green)\n",
    "    target_idx = 1\n",
    "    # Find a sample of digit 1\n",
    "    for i in range(len(test_full)):\n",
    "        img, lbl, _ = test_full[i]\n",
    "        if lbl == target_idx:\n",
    "            base_img = img.unsqueeze(0).to(device)\n",
    "            break\n",
    "            \n",
    "    fig, axes = plt.subplots(1, 10, figsize=(15, 2))\n",
    "    fig.suptitle(f\"Recolor Proof: {title} (True Label: {target_idx})\", y=1.1)\n",
    "    \n",
    "    results = []\n",
    "    model.eval()\n",
    "    \n",
    "    for c_idx in range(10):\n",
    "        # Hackily recolor the tensor\n",
    "        recolored = recolor_tensor(base_img, c_idx)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(recolored)\n",
    "            pred = logits.argmax(1).item()\n",
    "            \n",
    "        ax = axes[c_idx]\n",
    "        ax.imshow(recolored.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "        color_name = get_color_name(c_idx)\n",
    "        title_col = 'green' if pred == target_idx else 'red'\n",
    "        ax.set_title(f\"{color_name}\\nPred: {pred}\", color=title_col, fontsize=9)\n",
    "        ax.axis('off')\n",
    "        results.append(pred == target_idx)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"artifacts/standalone_run/recolor_proof_{title.replace(' ', '_')}.png\")\n",
    "    plt.close()\n",
    "    score = sum(results)\n",
    "    print(f\"{title} Result: {score}/10 correct across colors.\")\n",
    "\n",
    "print(\"Running Recolor Proof...\")\n",
    "run_recolor_proof(cheater_model, \"Cheater Model\")\n",
    "run_recolor_proof(robust_model, \"Robust Model\")\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# --- NEW: Task 3 - Grad-CAM Implementation ---\n",
    "import cv2\n",
    "\n",
    "class GradCAM:\n",
    "    \"\"\"\n",
    "    Implements Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Register hooks\n",
    "        # 1. Forward hook to capture feature maps (A_k)\n",
    "        target_layer.register_forward_hook(self.save_activation)\n",
    "        # 2. Backward hook to capture gradients (dy/dA_k)\n",
    "        target_layer.register_full_backward_hook(self.save_gradient)\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def __call__(self, x, class_idx=None):\n",
    "        self.model.eval()\n",
    "        output = self.model(x)\n",
    "        if class_idx is None:\n",
    "            class_idx = torch.argmax(output, dim=1).item()\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        target_score = output[:, class_idx]\n",
    "        target_score.backward(retain_graph=True)\n",
    "        \n",
    "        gradients = self.gradients\n",
    "        activations = self.activations\n",
    "        \n",
    "        # GAP of gradients -> weights\n",
    "        weights = torch.mean(gradients, dim=(2, 3), keepdim=True)\n",
    "        \n",
    "        # Weighted combination\n",
    "        cam = torch.sum(weights * activations, dim=1, keepdim=True)\n",
    "        cam = F.relu(cam)\n",
    "        \n",
    "        # Normalize\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-7)\n",
    "        return cam.detach(), class_idx\n",
    "\n",
    "def show_cam_on_image(img_tensor, cam_mask):\n",
    "    \"\"\"\n",
    "    Overlay Grad-CAM heatmap on the original image.\n",
    "    img_tensor: [3, H, W] (0-1)\n",
    "    cam_mask: [H, W] (0-1)\n",
    "    \"\"\"\n",
    "    img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    # Resize cam_mask (tensor) to match image size\n",
    "    heatmap = cv2.resize(cam_mask.cpu().numpy().squeeze(), (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    heatmap = heatmap[..., ::-1] # BGR to RGB\n",
    "    \n",
    "    cam = heatmap * 0.5 + img * 0.5\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(255 * cam)\n",
    "\n",
    "def run_gradcam_analysis(model, title):\n",
    "    print(f\"Running Grad-CAM Analysis for {title}...\")\n",
    "    \n",
    "    # Target Layer: Last Convolutional Layer\n",
    "    # SimpleCNN.conv3 is Sequential(Conv2d, BatchNorm, ReLU, MaxPool)\n",
    "    # We want the ReLU output (Index 2) which is before MaxPool.\n",
    "    # This gives returns 7x7 spatial resolution instead of 3x3.\n",
    "    target_layer = model.conv3[2]\n",
    "    grad_cam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Find a specific \"Trap\" image: Green 0 (Shape=0, Color=Green/1)\n",
    "    # 1. Find a 0 in test set\n",
    "    raw_img_0 = None\n",
    "    for i in range(len(test_full)):\n",
    "        img, lbl, _ = test_full[i]\n",
    "        if lbl == 0:\n",
    "            # We need the underlying grayscale shape.\n",
    "            # Approx: mean across channels of the biased image\n",
    "            raw_img_0 = img.mean(dim=0, keepdim=True) # [1, 28, 28]\n",
    "            break\n",
    "            \n",
    "    # 2. Color it Green. BiasedMNIST.COLORS[1] is Green.\n",
    "    green_rgb = torch.tensor(BiasedMNIST.COLORS[1]).view(3, 1, 1).to(device)\n",
    "    \n",
    "    # Move raw_img to device\n",
    "    raw_img_0 = raw_img_0.to(device)\n",
    "    \n",
    "    green_0_img = raw_img_0 * green_rgb\n",
    "    noise = torch.rand_like(green_0_img) * 0.1\n",
    "    green_0_img = torch.clamp(green_0_img + noise, 0, 1)\n",
    "    \n",
    "    input_tensor = green_0_img.unsqueeze(0) # [1, 3, 28, 28]\n",
    "    \n",
    "    # Predict\n",
    "    model.eval()\n",
    "    logits = model(input_tensor)\n",
    "    pred_idx = logits.argmax(1).item()\n",
    "    \n",
    "    print(f\"[{title}] Input: Green 0 (Shape=0, Color=1). Prediction: {pred_idx}\")\n",
    "    \n",
    "    # Grad-CAM for Predicted Class\n",
    "    # (If Cheater predicts 1, we explain 1. If Robust predicts 0, we explain 0.)\n",
    "    mask_pred, _ = grad_cam(input_tensor, class_idx=pred_idx)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    \n",
    "    # Original\n",
    "    axs[0].imshow(green_0_img.cpu().permute(1, 2, 0))\n",
    "    axs[0].set_title(f\"Trap Input\\nPred: {pred_idx}\")\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    # Heatmap\n",
    "    # Heatmap\n",
    "    # Resize to 28x28 for better visualization (bilinear interpolation)\n",
    "    heatmap_resized = cv2.resize(mask_pred.cpu().squeeze().numpy(), (28, 28))\n",
    "    axs[1].imshow(heatmap_resized, cmap='jet')\n",
    "    axs[1].set_title(f\"Grad-CAM (Target: {pred_idx})\")\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    cam_img = show_cam_on_image(green_0_img, mask_pred)\n",
    "    axs[2].imshow(cam_img)\n",
    "    axs[2].set_title(\"Overlay\")\n",
    "    axs[2].axis('off')\n",
    "    \n",
    "    save_path = f\"artifacts/standalone_run/gradcam_{title.replace(' ', '_')}.png\"\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved Grad-CAM to {save_path}\")\n",
    "\n",
    "print(\"\\n--- Generating Grad-CAM Interpretability ---\")\n",
    "run_gradcam_analysis(cheater_model, \"Cheater Model\")\n",
    "run_gradcam_analysis(robust_model, \"Robust Model\")\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# --- NEW: Task 2 - The Prober (Internal Neurons) ---\n",
    "\n",
    "print(\"--- Task 2: The Prober (Internal Neurons) ---\")\n",
    "\n",
    "def get_fft_scale(h, w, decay_power=1.0):\n",
    "    d = np.sqrt(\n",
    "        np.fft.fftfreq(h)[:, None]**2 +\n",
    "        np.fft.fftfreq(w)[None, :]**2\n",
    "    )\n",
    "    scale = 1.0 / np.maximum(d, 1.0 / max(h, w))**decay_power\n",
    "    scale = torch.tensor(scale).float()[None, None, ..., None]\n",
    "    return scale\n",
    "\n",
    "class FourierParam(nn.Module):\n",
    "    def __init__(self, shape, decay_power=1.0):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "        h, w = shape[-2], shape[-1]\n",
    "        self.scale = get_fft_scale(h, w, decay_power)\n",
    "        # Random initialization in freq domain\n",
    "        self.spectrum = nn.Parameter(torch.randn(*shape, 2) * 0.01)\n",
    "\n",
    "    def forward(self, device):\n",
    "        scale = self.scale.to(device)\n",
    "        # Handle complex view for compatibility\n",
    "        if hasattr(torch, 'view_as_complex'):\n",
    "             spectrum = torch.view_as_complex(self.spectrum)\n",
    "        else:\n",
    "             # Fallback\n",
    "             spectrum = torch.complex(self.spectrum[..., 0], self.spectrum[..., 1])\n",
    "             \n",
    "        image = torch.fft.irfftn(spectrum, s=self.shape)\n",
    "        # Scale to decent starting range\n",
    "        image = image * scale.squeeze(-1)\n",
    "        # Sigmoid to bind to 0-1 (roughly)\n",
    "        return torch.sigmoid(image)\n",
    "\n",
    "class FeatureVisualizer:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model.eval().to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def optimize(self, layer_name, channel, steps=200, lr=0.05):\n",
    "        # Initial image in Frequency Domain\n",
    "        # Shape: (1, 3, 28, 28)\n",
    "        param = FourierParam(shape=(1, 3, 28, 28), decay_power=1.2).to(self.device).train()\n",
    "        optimizer = torch.optim.Adam(param.parameters(), lr=lr)\n",
    "        \n",
    "        # Hook target layer\n",
    "        activation = {}\n",
    "        def hook_fn(module, input, output):\n",
    "            # output might be a tuple if it's not the final layer? \n",
    "            # Conv2d output is tensor. Sequential output is tensor.\n",
    "            activation['act'] = output\n",
    "        \n",
    "        # Find layer by name\n",
    "        # model.conv1 is a Sequential. We want output of ReLU inside it? \n",
    "        # Or output of the block.\n",
    "        # \"conv1\" -> model.conv1\n",
    "        target_layer = dict([*self.model.named_modules()])[layer_name]\n",
    "        handle = target_layer.register_forward_hook(hook_fn)\n",
    "        \n",
    "        try:\n",
    "            for i in range(steps):\n",
    "                optimizer.zero_grad()\n",
    "                img = param(self.device)\n",
    "                \n",
    "                # Simple jitter\n",
    "                ox, oy = np.random.randint(-2, 3, 2)\n",
    "                img_jittered = torch.roll(img, shifts=(ox, oy), dims=(-2, -1))\n",
    "                \n",
    "                _ = self.model(img_jittered)\n",
    "                \n",
    "                # Get target activation: [1, Channels, H, W]\n",
    "                # Maximize mean activation of specific channel\n",
    "                act = activation['act'][:, channel, :, :]\n",
    "                loss = -act.mean()\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                          \n",
    "        finally:\n",
    "            handle.remove()\n",
    "            \n",
    "        final_img = param(self.device).detach().cpu()\n",
    "        return final_img\n",
    "\n",
    "def run_feature_visualization(model, output_dir=\"artifacts/standalone_run\"):\n",
    "    print(\"Generating Feature Visualizations for Cheater Model...\")\n",
    "    \n",
    "    vis = FeatureVisualizer(model, device)\n",
    "    \n",
    "    # 1. Conv1 (Show 8 filters)\n",
    "    # Architecture: Conv1 -> 32 channels. We show first 8.\n",
    "    print(\"Optimizing Conv1 features...\")\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    fig.suptitle(\"Feature Visualization: Conv1 (First 8 Filters)\")\n",
    "    \n",
    "    for i in range(8):\n",
    "        # Target 'conv1' which is a Sequential block\n",
    "        # The hook captures output of MaxPool2d(2) inside conv1 block.\n",
    "        dream = vis.optimize(\"conv1\", i, steps=200)\n",
    "        \n",
    "        img = dream.squeeze(0).permute(1, 2, 0).numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        ax = axes[i // 4, i % 4]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Filter {i}\")\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"feature_vis_conv1.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Conv2 (Show 8 filters)\n",
    "    # Architecture: Conv2 -> 64 channels. Show first 8.\n",
    "    print(\"Optimizing Conv2 features...\")\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    fig.suptitle(\"Feature Visualization: Conv2 (First 8 Filters)\")\n",
    "    \n",
    "    for i in range(8):\n",
    "        dream = vis.optimize(\"conv2\", i, steps=200)\n",
    "        \n",
    "        img = dream.squeeze(0).permute(1, 2, 0).numpy()\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        \n",
    "        ax = axes[i // 4, i % 4]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"Filter {i}\")\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"feature_vis_conv2.png\"))\n",
    "    plt.close()\n",
    "    print(\"Saved feature visualizations to artifacts/standalone_run/\")\n",
    "\n",
    "# Run Feature Vis on Cheater Model\n",
    "# (Cheater model is mostly looking for colors, so expect color blobs)\n",
    "run_feature_visualization(cheater_model)\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
