{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cba92c50",
   "metadata": {},
   "source": [
    "# Task 2: The Prober (Feature Visualization)\n",
    "## \"Can you see what the neurons are seeing?\"\n",
    "\n",
    "In this notebook, we use **Feature Visualization** (inspired by OpenAI Microscope) to understand what specific neurons in our \"Cheater\" model are looking for.\n",
    "We optimize an input image (using Fourier parameterization) to maximize the activation of specific channels.\n",
    "\n",
    "### Hypothesis\n",
    "- **Early Layers (Conv1)**: Should detect simple features like edges or solid colors (Red/Green).\n",
    "- **Middle Layers (Conv2)**: Should detect more complex combinations (Curves + Colors).\n",
    "- **Polysemanticity**: We expect some neurons to fire for seemingly unrelated concepts (e.g., \"Red\" AND \"Vertical Lines\") because the model learned shortcuts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d5f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.models.simple_cnn import SimpleCNN\n",
    "from src.vis_utils import FeatureVisualizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde098a7",
   "metadata": {},
   "source": [
    "## 1. Load the Cheater Model\n",
    "We load the same model architecture and weights trained in Task 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a486c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model exactly as in Task 1\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 7 * 7)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# Ideally we load 'state_dict' but since we didn't save it explicitly to a file in Task 1 notebook,\n",
    "# we might need to re-train briefly OR just re-run the training logic here if we want the EXACT same model.\n",
    "# NOTE: For this demonstration, we will re-train quickly to ensure we have a valid Cheater model instance in memory.\n",
    "# In a real pipeline, we'd save/load 'cheater_model.pth'.\n",
    "\n",
    "from src.data.biased_mnist import BiasedMNIST\n",
    "import torch.optim as optim\n",
    "\n",
    "print(\"Re-training Cheater (Quickly) to ensure state...\")\n",
    "train_dataset = BiasedMNIST(root='./data', train=True, download=True, bias_ratio=0.995)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(2): # Just 2 epochs to get the weights roughly right\n",
    "    for images, labels, colors in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "print(\"Model re-trained/loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a434e4a",
   "metadata": {},
   "source": [
    "## 2. Probing Neurons\n",
    "We create a `FeatureVisualizer` instance. This helper uses:\n",
    "- **Fourier Parameterization**: To generate smooth, valid images.\n",
    "- **Jitter Robustness**: To find invariant features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a54413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = FeatureVisualizer(model, device)\n",
    "\n",
    "def show_dream(img_tensor, title=\"\"):\n",
    "    img = img_tensor.squeeze(0).permute(1, 2, 0).numpy()\n",
    "    # Normalize to 0-1 just in case, though sigmoid handles it mostly\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e92a22",
   "metadata": {},
   "source": [
    "### Experiment A: Conv1 Filters (Simple Features)\n",
    "Conv1 has 8 channels. Let's see what they look like.\n",
    "We expect detailed textures or solid colors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(8):\n",
    "    print(f\"Optimizing Conv1 Channel {i}...\")\n",
    "    dream, _ = visualizer.optimize(\"conv1\", i, steps=300)\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    show_dream(dream, f\"Conv1 Ch {i}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0a647",
   "metadata": {},
   "source": [
    "### Experiment B: Conv2 Filters (Complex Features)\n",
    "Conv2 has 16 channels. These should correspond to higher-level concepts.\n",
    "Since our model is a \"Cheater\", we hypothesize some of these will be **Pure Color Detectors** (e.g., just a red blob).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f79b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "for i in range(16):\n",
    "    print(f\"Optimizing Conv2 Channel {i}...\")\n",
    "    dream, _ = visualizer.optimize(\"conv2\", i, steps=400)\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    show_dream(dream, f\"Conv2 Ch {i}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138fc246",
   "metadata": {},
   "source": [
    "### Experiment C: Polysemanticity Probe\n",
    "Let's take a specific neuron that looks \"messy\" or interesting from above and run it multiple times with different random seeds. \n",
    "If it consistently converges to the *same* image, it's likely monosemantic. \n",
    "If it converges to *different* types of images (e.g. sometimes red, sometimes a curve), it's polysemantic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebda6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_channel = 5 # Arbitrary choice, change based on observation\n",
    "print(f\"Probing Polysemanticity of Conv2 Channel {target_channel}...\")\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "for run in range(4):\n",
    "    dream, _ = visualizer.optimize(\"conv2\", target_channel, steps=400)\n",
    "    plt.subplot(1, 4, run+1)\n",
    "    show_dream(dream, f\"Run {run}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
